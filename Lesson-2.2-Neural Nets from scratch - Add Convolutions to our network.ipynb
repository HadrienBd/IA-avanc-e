{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Lesson 2.2 Neural Nets from scratch - Add Convolutions to our network.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHmUeS9356UL"
      },
      "source": [
        "# Implement convolutions in a whole net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPiIPFJwbMf6",
        "outputId": "50980079-9cb0-4839-8c33-92efc9cc5d69"
      },
      "source": [
        "pip install flake8 pycodestyle_magic"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flake8 in /usr/local/lib/python3.7/dist-packages (3.9.2)\n",
            "Requirement already satisfied: pycodestyle_magic in /usr/local/lib/python3.7/dist-packages (0.5)\n",
            "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from flake8) (0.6.1)\n",
            "Requirement already satisfied: pyflakes<2.4.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from flake8) (2.3.1)\n",
            "Requirement already satisfied: pycodestyle<2.8.0,>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from flake8) (2.7.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from flake8) (4.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->flake8) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->flake8) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF6ih0YQ56UO"
      },
      "source": [
        "%load_ext pycodestyle_magic\n",
        "%flake8_on"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIGHV0cK56UP"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.datasets import MNIST\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAtn4bIV56UQ"
      },
      "source": [
        "# Get Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGXb2c3G56UQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "530386f1-0522-4892-c438-6ddbe29f85e4"
      },
      "source": [
        "# Get the data using pytorch MNIST function\n",
        "trainset = MNIST('../../', download=True, train=True)\n",
        "testset = MNIST('../../', download=True, train=False)\n",
        "\n",
        "# Store the labels\n",
        "y_trainset = trainset.targets\n",
        "y_testset = testset.targets\n",
        "\n",
        "# reshape and pass to float32\n",
        "train = trainset.data.reshape(60000, -1)\n",
        "test = testset.data.reshape(10000, -1)\n",
        "trainset = train.to(torch.float32)\n",
        "testset = test.to(torch.float32)\n",
        "\n",
        "# Normalize\n",
        "m, std = trainset.mean(), trainset.std()\n",
        "trainset = (trainset - m) / std\n",
        "testset = (testset - m) / std\n",
        "\n",
        "print(trainset.mean(), trainset.std())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.8892e-08) tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW6AJBp456UR"
      },
      "source": [
        "# Define useful classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGJh8B8s56UR"
      },
      "source": [
        "class Dataset():\n",
        "    # A convenience class to have all your data stored at the same place\n",
        "    # common practice\n",
        "    def __init__(self, x, y): self.x, self.y = x, y\n",
        "    def __len__(self): return len(self.x)\n",
        "    def __getitem__(self, i): return self.x[i], self.y[i] "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00UZXKjw56US"
      },
      "source": [
        "class DataLoader():\n",
        "    # helps us do minibatch training\n",
        "    def __init__(self, data, bs):\n",
        "        self.data, self.bs = data, bs\n",
        "\n",
        "    def __iter__(self):\n",
        "        for i in range(0, len(self.data), self.bs):\n",
        "            yield self.data[i:i+self.bs]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cjTjser56US"
      },
      "source": [
        "class Optimizer():\n",
        "    # is used to get rid of code inside the training loop\n",
        "    def __init__(self, parameters, lr=0.4):\n",
        "        self.parameters, self.lr = list(parameters), lr\n",
        "\n",
        "    def step(self):\n",
        "        with torch.no_grad():\n",
        "            for p in self.parameters:\n",
        "                p -= p.grad * self.lr\n",
        "\n",
        "    def zero_grad(self):\n",
        "        for p in self.parameters:\n",
        "            p.grad.zero_()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLH-ZSfS56UT"
      },
      "source": [
        "def accuracy(output, target):\n",
        "    return (torch.argmax(output, dim=1) == target).float().mean()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9MJ7CI056UT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dc505ed-4fca-4326-ecf1-f15ba02cb9bc"
      },
      "source": [
        "# explain accuracy\n",
        "my_output = torch.randn(64, 10)\n",
        "# my_output\n",
        "torch.argmax(my_output)  # only one number\n",
        "torch.argmax(my_output, dim=1)  # 64 numbers (one pred for each image)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 6, 1, 1, 6, 2, 5, 2, 9, 2, 1, 0, 5, 6, 5, 9, 1, 8, 9, 3, 5, 9, 3, 3,\n",
              "        0, 2, 6, 8, 3, 9, 0, 9, 2, 4, 8, 2, 0, 1, 9, 4, 9, 4, 1, 0, 8, 8, 1, 9,\n",
              "        5, 8, 0, 5, 2, 4, 6, 2, 5, 4, 8, 7, 4, 6, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcFnYEpm56UU"
      },
      "source": [
        "EPOCHS = 5\n",
        "lr = 0.3\n",
        "bs = 64\n",
        "loss_func = F.cross_entropy\n",
        "\n",
        "# here we will later download and assign pre-trained models\n",
        "learner = nn.Sequential(\n",
        "    nn.Linear(784, 250),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(250, 100),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(100, 10)\n",
        ")\n",
        "\n",
        "# Your nn.Sequential has a .parameters() attribute !\n",
        "# so the Optimizer find alone all the tensors that require gradients ! \n",
        "opt = Optimizer(learner.parameters(), lr=lr)\n",
        "\n",
        "my_data = Dataset(trainset, y_trainset)\n",
        "train_dataloader = DataLoader(my_data, bs)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH9pLDOZ56UU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69f6009a-ef67-42f2-c855-ccf30547a259"
      },
      "source": [
        "for i in range(EPOCHS):\n",
        "    for xb, yb in train_dataloader:\n",
        "        output = learner(xb)\n",
        "        loss = loss_func(output, yb)\n",
        "        # backward pass:\n",
        "        loss.backward()\n",
        "        \n",
        "        # we've removed all the mess into opt: \n",
        "        opt.step() #replaces a.weight -= a.weight.grad * lr\n",
        "        opt.zero_grad()\n",
        "    print(loss)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0269, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0085, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0017, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0001, grad_fn=<NllLossBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1vvDrUV56UV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c3c5802-037d-41a2-8b07-45ea87dd6430"
      },
      "source": [
        "# careful, we asked for a 64 batch size, but the last batch is 32 \n",
        "xb.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekW2TH7Q56UW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1409fbbf-7caa-4d56-d212-7b8800858e43"
      },
      "source": [
        "# 937 batches of 64, and a half batch of 64, hence 32 \n",
        "60000 / 64 "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "937.5"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "enp6jZX756UW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60840459-8613-439e-ac96-05c2160be05b"
      },
      "source": [
        "60000 % 64"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2lWr_fS56UX"
      },
      "source": [
        "# Adding Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sM9hlVl-56UX"
      },
      "source": [
        "train, valid = trainset[0:50000, :], trainset[50000:, :]\n",
        "y_train, y_valid = y_trainset[0:50000], y_trainset[50000:]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHd-7YIW56UX"
      },
      "source": [
        "We'll now start using Pytorch's DataLoader because it also has a random sampler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEbY2vWh56UY"
      },
      "source": [
        "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stwiK-nx56UY"
      },
      "source": [
        "train_dl = DataLoader(Dataset(train, y_train), batch_size=64, shuffle=True)\n",
        "valid_dl = DataLoader(Dataset(valid, y_valid), 64)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH1HdAJY56UY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e60a57da-7e54-48e1-b026-ca0a80f70016"
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    # learner.train() puts the model in train mode (it calculates gradients)\n",
        "    learner.train()\n",
        "    for xb, yb in train_dl:\n",
        "        output = learner(xb)\n",
        "        loss = loss_func(output, yb)\n",
        "        # backward pass:\n",
        "        loss.backward()\n",
        "        \n",
        "        # we've removed all the mess into opt: \n",
        "        opt.step() #replaces a.weight -= a.weight.grad * lr\n",
        "        opt.zero_grad()\n",
        "\n",
        "    # learner.eval() puts the model in eval mode (it calculates gradients)\n",
        "    learner.eval()\n",
        "    with torch.no_grad():\n",
        "        total_loss, total_acc = 0., 0.\n",
        "        for xb, yb in valid_dl:\n",
        "            pred = learner(xb)\n",
        "            total_loss += loss_func(pred, yb)\n",
        "            total_acc += accuracy(pred, yb)\n",
        "            \n",
        "        # we calculate above to have metrics during training, but note we are\n",
        "        # NOT DOING back propagation\n",
        "        n_entries = len(valid_dl)\n",
        "        print('epoch', epoch,\n",
        "              'loss:', (total_loss/n_entries).item(),\n",
        "              'accuracy:', (total_acc/n_entries).item()\n",
        "              )"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 loss: 0.036242078989744186 accuracy: 0.9890525341033936\n",
            "epoch 1 loss: 0.029556408524513245 accuracy: 0.9922372698783875\n",
            "epoch 2 loss: 0.02887069806456566 accuracy: 0.9908439517021179\n",
            "epoch 3 loss: 0.03517087176442146 accuracy: 0.9903463125228882\n",
            "epoch 4 loss: 0.033577993512153625 accuracy: 0.9901472926139832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF2spbno56UZ"
      },
      "source": [
        "# Adding convolutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJqBJU9M56UZ"
      },
      "source": [
        "Now adding convolutions is just a matter of changing the sequence of layers in nn.Sequential"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzuxKk8o56UZ"
      },
      "source": [
        "# Use Jupyter Notebook shortcuts to access the doc and see how to use Conv2d\n",
        "# ??nn.Conv2d"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4Z19x4i56Ua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89eb3f00-54a5-4421-95b4-009fa2736434"
      },
      "source": [
        "xb.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6zd-eJs56Ua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb5d790e-6eb6-46b0-aafb-83f461cb4a79"
      },
      "source": [
        "# We can basically replace the nn.Linear with this:\n",
        "my_layer = nn.Conv2d(in_channels=1, out_channels=9, kernel_size=3, padding=1)\n",
        "\n",
        "# PAY ATTENTION HERE\n",
        "# Except nn.Conv2d takes input of shape N * Channels * Height * Width\n",
        "# (as seen in the doc if you uncomment above)\n",
        "# and we had no channels so far (MNIST isn't RVB), so we add an extra channel\n",
        "my_layer(xb.reshape(16, 1, 28, 28)).shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 9, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aEwlms456Ua"
      },
      "source": [
        "# We also need to flatten out the output of the successive convolutions\n",
        "# before we pass it to a nn.Linear()\n",
        "# we add a Lambda layer (pretty much like a lambda function) to do that\n",
        "\n",
        "\n",
        "class Lambda(nn.Module):\n",
        "    def __init__(self, func):\n",
        "        super().__init__()\n",
        "        self.func = func\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.func(x)\n",
        "\n",
        "\n",
        "def flatten(x):\n",
        "    return x.view(x.shape[0], -1)\n",
        "\n",
        "# we can also use that Lambda class to resize the data as in the above cell\n",
        "def mnist_resize(x): return x.view(-1, 1, 28, 28) "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78j5M91k56Ub"
      },
      "source": [
        "EPOCHS = 6\n",
        "lr = 0.4\n",
        "bs = 64\n",
        "loss_func = F.cross_entropy\n",
        "\n",
        "# I created the network for you and we'll follow \n",
        "# the code together ;) \n",
        "learner = nn.Sequential(\n",
        "    Lambda(mnist_resize),  # we can do the reshape here\n",
        "    nn.Conv2d(in_channels=1, out_channels=8,\n",
        "              kernel_size=3, stride=1, padding=1),  # bs*8*28*28\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(8, 16, 3, 2, 1),  # bs*16*14*14\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 32, 3, 2, 1),  # bs * 32 * 7 * 7\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(32, 64, 3, 2, 1),  # bs * 64 * 4 * 4\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(64, 64, 3, 2, 1),  # bs * 64 * 2 * 2\n",
        "    nn.AdaptiveAvgPool2d(1),\n",
        "    Lambda(flatten),\n",
        "    nn.Linear(64, 10)\n",
        ")\n",
        "\n",
        "opt = Optimizer(learner.parameters(), lr=lr)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzPO04cI56Ub",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ca2905d-2924-444c-e818-a718e2f334e6"
      },
      "source": [
        "# A cool thing is that the train loop doesn't need to change\n",
        "for epoch in range(EPOCHS):\n",
        "    # learner.train() puts the model in train mode (it calculates gradients)\n",
        "    learner.train()\n",
        "    \n",
        "    for xb, yb in train_dl:\n",
        "        # again, practice \n",
        "        output = learner(xb)\n",
        "        loss = loss_func(output, yb)\n",
        "        # backward pass:\n",
        "        loss.backward()\n",
        "        \n",
        "        # we've removed all the mess into opt: \n",
        "        opt.step() #replaces a.weight -= a.weight.grad * lr\n",
        "        opt.zero_grad()\n",
        "\n",
        "    # put your learner in eval mode \n",
        "    \n",
        "    with torch.no_grad():\n",
        "        total_loss, total_acc = 0., 0.\n",
        "        for xb, yb in valid_dl:\n",
        "            pred = learner(xb)\n",
        "            total_loss += loss_func(pred, yb)\n",
        "            total_acc += accuracy(pred, yb)\n",
        "        n_entries = len(valid_dl)\n",
        "        print('epoch', epoch,\n",
        "              'loss:', (total_loss/n_entries).item(),\n",
        "              'accuracy:', (total_acc/n_entries).item()\n",
        "              )"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 loss: 0.11545221507549286 accuracy: 0.9674562215805054\n",
            "epoch 1 loss: 0.08085844665765762 accuracy: 0.9774084687232971\n",
            "epoch 2 loss: 0.058038607239723206 accuracy: 0.9831807613372803\n",
            "epoch 3 loss: 0.06289549171924591 accuracy: 0.9802945852279663\n",
            "epoch 4 loss: 0.07366625219583511 accuracy: 0.9783041477203369\n",
            "epoch 5 loss: 0.05670349299907684 accuracy: 0.9851711988449097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "in_J3ISq56Ub"
      },
      "source": [
        "So, we added convolutions, but two problems arose:\n",
        "\n",
        "* the training isn't very smooth. We'll need to add some regularization\n",
        "* the training is way slower than before. We'll need to start using the GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wif35kDq56Uc"
      },
      "source": [
        "### Sanity check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4KV77VJ56Uc"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHb-af5U56Uc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "96cc7271-c167-480d-c09a-a166c0f719da"
      },
      "source": [
        "seven = testset.data[17].reshape(28, 28)\n",
        "cut_seven = seven[:, 5:22]\n",
        "shifted_seven = torch.zeros(28, 28)\n",
        "shifted_seven[:, :] = -0.4241\n",
        "shifted_seven[:, 0:17] = cut_seven\n",
        "plt.imshow(shifted_seven.numpy())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa131a8b3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCorPK8R56Ud",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08c2f1da-64c0-4004-dfc0-b5473fb3b2f2"
      },
      "source": [
        "learner(seven).argmax(dim=-1), learner(shifted_seven).argmax(dim=-1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([7]), tensor([7]))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8d7RTak56Ud"
      },
      "source": [
        "# In practice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq9DZPvm56Ud"
      },
      "source": [
        "from torchvision.models.resnet import resnet18"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KicEvvxU56Ud",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f55fbc9-8109-4598-b9b7-38635df75836"
      },
      "source": [
        "resnet18()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQr_LySC56Ue"
      },
      "source": [
        "# Next: FastAI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSkHwJPk56Ue"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    }
  ]
}